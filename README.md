# ğŸŒ¾ Wheat Seeds Classification Using Multi-Layer Perceptron

> High-precision classification of wheat seed varieties using deep learning and geometric feature analysis

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-CC%20BY%204.0-green.svg)](https://creativecommons.org/licenses/by/4.0/)

## ğŸ“‘ Table of Contents

- [Project Overview](#-project-overview)
- [Key Highlights](#-key-highlights)
- [Dataset Information](#-dataset-information)
- [Getting Started](#-getting-started)
- [Model Architecture](#-model-architecture)
- [Performance Results](#-performance-results)
- [Machine Learning Pipeline](#-machine-learning-pipeline)
- [Project Structure](#-project-structure)
- [Academic Context](#-academic-context)
- [Important Links](#-important-links)
- [Technologies Used](#-technologies-used)

## ğŸ“Š Project Overview

This project implements an optimized Multi-Layer Perceptron (MLP) neural network to classify three varieties of wheat seedsâ€”**Kama**, **Rosa**, and **Canadian**â€”using seven geometric features derived from soft X-ray imaging techniques.

### ğŸ† Achievement

**Model Accuracy:** `99.91% Â± 0.07%` (5-Fold Cross-Validation)

## âœ¨ Key Highlights

| Feature                       | Description                                                             |
| ----------------------------- | ----------------------------------------------------------------------- |
| ğŸ¤– **Automated Pipeline**     | End-to-end automation from data acquisition to model evaluation         |
| ğŸ”„ **Smart Preprocessing**    | StandardScaler normalization with noise injection augmentation (Ïƒ=0.02) |
| ğŸ§  **Optimized Architecture** | 7â†’64â†’32â†’3 MLP with strategic Dropout (0.2) regularization               |
| âœ… **Rigorous Validation**    | Stratified 5-Fold Cross-Validation ensuring robust performance          |
| ğŸ“ˆ **Production Ready**       | Exceptional stability (CV < 1%) with 99.91% mean accuracy               |

## ğŸ“ Dataset Information

**Source:** [UCI Machine Learning Repository - Seeds Dataset](https://archive.ics.uci.edu/dataset/236/seeds)

| Property           | Details                                     |
| ------------------ | ------------------------------------------- |
| **Total Samples**  | 210 (perfectly balanced: 70 per class)      |
| **Features**       | 7 geometric measurements from X-ray imaging |
| **Target Classes** | 3 wheat varieties (Kama, Rosa, Canadian)    |
| **Data Quality**   | Clean, no missing values                    |

**Citation:** Charytanowicz, M., Niewczas, J., Kulczycki, P., Kowalski, P.A., Åukasik, S., & Å»ak, S. (2010). _Seeds Dataset_. UCI Machine Learning Repository. DOI: https://doi.org/10.24432/C5H30K

### ğŸ“ Feature Descriptions

| #   | Feature Name              | Description                  | Formula                  |
| --- | ------------------------- | ---------------------------- | ------------------------ |
| 1   | **Area**                  | Total area of seed kernel    | -                        |
| 2   | **Perimeter**             | Circumference of seed kernel | -                        |
| 3   | **Compactness**           | Roundness measure            | $C = \frac{4\pi A}{P^2}$ |
| 4   | **Kernel Length**         | Longest dimension of kernel  | -                        |
| 5   | **Kernel Width**          | Widest dimension of kernel   | -                        |
| 6   | **Asymmetry Coefficient** | Measure of kernel symmetry   | -                        |
| 7   | **Groove Length**         | Length of central groove     | -                        |

## ğŸš€ Getting Started

### ğŸ“‹ Prerequisites

**System Requirements:**

- Python 3.8 or higher
- pip (Python package installer)
- 2GB RAM minimum
- Internet connection (for dataset download)

**Installing Dependencies:**

All required packages are listed in `requirements.txt`. Install them using:

```bash
pip install -r requirements.txt
```

**Included Packages:**

- `pandas>=1.3.0` - Data manipulation and analysis
- `numpy>=1.21.0` - Numerical computing
- `scikit-learn>=1.0.0` - Machine learning utilities
- `tensorflow>=2.8.0` - Deep learning framework
- `matplotlib>=3.4.0` - Data visualization
- `seaborn>=0.11.0` - Statistical visualization
- `jupyter>=1.0.0` - Notebook environment

<details>
<summary><b>Manual Installation (Alternative)</b></summary>

If you prefer to install packages individually:

```bash
pip install pandas numpy scikit-learn tensorflow matplotlib seaborn jupyter
```

</details>

### â–¶ï¸ Running the Project

1. **Clone the repository:**

   ```bash
   git clone https://github.com/prumucena1979/MLFINAL.git
   cd MLFINAL
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Launch Jupyter Notebook:**

   ```bash
   jupyter notebook
   ```

4. **Open and run the notebook:**
   - Navigate to `Turnin/notebook/Seeds_ML_FINALPRJ_NF1002000.ipynb`
   - Run all cells sequentially (Cell â†’ Run All)
   - Dataset will be automatically downloaded from UCI Repository on first run

> **Note:** The notebook includes comprehensive documentation and visualizations for each step.

## ğŸ§  Model Architecture

The neural network employs a feed-forward architecture optimized for this classification task:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Layer (7 features)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hidden Layer 1: Dense(64) + ReLU   â”‚
â”‚  Regularization: Dropout(0.2)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hidden Layer 2: Dense(32) + ReLU   â”‚
â”‚  Regularization: Dropout(0.2)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Layer: Dense(3) + Softmax   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Model Specifications:**

- **Total Parameters:** 2,691 (all trainable)
  - Inputâ†’Hidden1: 7Ã—64 + 64 = 512
  - Hidden1â†’Hidden2: 64Ã—32 + 32 = 2,080
  - Hidden2â†’Output: 32Ã—3 + 3 = 99
- **Optimizer:** Adam (adaptive learning rate)
- **Loss Function:** Sparse Categorical Cross-Entropy
- **Regularization:** Dropout (0.2) + Early Stopping (patience=15)

## ğŸ“ˆ Performance Results

### ğŸ¯ Cross-Validation Metrics (5-Fold CV)

| Metric                       | Value             | Interpretation                      |
| ---------------------------- | ----------------- | ----------------------------------- |
| **Mean Accuracy**            | **99.91%**        | Near-perfect classification         |
| **Standard Deviation**       | 0.07%             | Exceptional consistency             |
| **Coefficient of Variation** | 0.07%             | Highly stable performance           |
| **95% Confidence Interval**  | [99.77%, 100.00%] | Reliable upper and lower bounds     |
| **Min Accuracy**             | 99.81%            | Worst-case scenario still excellent |
| **Max Accuracy**             | 100.00%           | Perfect classification achieved     |

### ğŸ”§ Implementation Details

<details>
<summary><b>Click to expand technical specifications</b></summary>

#### Data Preprocessing

- **Normalization:** StandardScaler (zero mean, unit variance)
- **Augmentation:** Gaussian noise injection (Ïƒ=0.02)
- **Split Strategy:** Stratified sampling preserving class distribution

#### Model Configuration

- **Architecture:** MLP with 2 hidden layers (64â†’32 neurons)
- **Activation Functions:** ReLU (hidden), Softmax (output)
- **Regularization:** Dropout (20% rate) + Early Stopping (patience=15)
- **Optimizer:** Adam with default learning rate
- **Batch Size:** 16
- **Max Epochs:** 100

#### Validation Strategy

- **Method:** Stratified 5-Fold Cross-Validation
- **Shuffling:** Enabled with fixed random seed for reproducibility
- **Metrics:** Accuracy, Precision, Recall, F1-Score

</details>

## ğŸ”„ Machine Learning Pipeline

The project follows a systematic, reproducible workflow:

```mermaid
graph TD
    A[ğŸ“¥ Data Acquisition] --> B[ğŸ”§ Preprocessing]
    B --> C[ğŸ”„ Data Augmentation]
    C --> D[ğŸ§  Model Design]
    D --> E[ğŸ‹ï¸ Training]
    E --> F[âš™ï¸ Hyperparameter Tuning]
    F --> G[âœ… Cross-Validation]
    G --> H[ğŸ“Š Performance Evaluation]

    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fff3e0
    style F fill:#fce4ec
    style G fill:#e0f2f1
    style H fill:#f1f8e9
```

| Step                         | Process                             | Output                    |
| ---------------------------- | ----------------------------------- | ------------------------- |
| **1. Data Acquisition**      | Auto-download from UCI Repository   | Raw dataset (210 samples) |
| **2. Preprocessing**         | StandardScaler normalization        | Normalized features       |
| **3. Data Augmentation**     | Gaussian noise injection            | Augmented training set    |
| **4. Model Design**          | Define MLP architecture (7â†’64â†’32â†’3) | Compiled model            |
| **5. Training**              | 100 epochs with early stopping      | Trained weights           |
| **6. Hyperparameter Tuning** | Dropout comparison (0.2 vs 0.4)     | Optimal configuration     |
| **7. Validation**            | Stratified 5-Fold CV                | Performance metrics       |
| **8. Evaluation**            | Statistical analysis                | Final report              |

## ğŸ“‚ Project Structure

```
MLFINAL/
â”œâ”€â”€ ğŸ““ Turnin/
â”‚   â”œâ”€â”€ notebook/
â”‚   â”‚   â””â”€â”€ Seeds_ML_FINALPRJ_NF1002000.ipynb    # ğŸ¯ Main Jupyter Notebook (Final Submission)
â”‚   â”œâ”€â”€ Project Report/                           # ğŸ“„ Comprehensive project documentation
â”‚   â””â”€â”€ VerificationVideo/                        # ğŸ¥ Video demonstration of implementation
â”‚
â”œâ”€â”€ ğŸ’¾ DATASET/
â”‚   â””â”€â”€ seeds/
â”‚       â””â”€â”€ seeds_dataset.txt                     # Local backup of UCI dataset
â”‚
â”œâ”€â”€ ğŸ“‹ Rubrics_n_Requirements/                    # Assignment guidelines and rubrics
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ bkp/                                       # Backup and archived versions
â”‚
â”œâ”€â”€ ğŸ“– README.md                                  # This documentation file
â”œâ”€â”€ ğŸ“¦ requirements.txt                           # Python dependencies
â”œâ”€â”€ ğŸ“Š Notebook_Analysis_Report.md                # Comprehensive notebook analysis
â”‚
â””â”€â”€ ğŸš« .gitignore                                 # Git version control exclusions
```

### ğŸ““ Main Notebook Contents

The primary notebook (`Seeds_ML_FINALPRJ_NF1002000.ipynb`) includes:

1. **Introduction & Setup** - Problem statement and dependencies
2. **Data Acquisition** - Automated UCI dataset loading
3. **Exploratory Data Analysis** - Statistical summaries and visualizations
4. **Data Preprocessing** - Scaling and augmentation techniques
5. **Model Development** - Architecture design and compilation
6. **Training Process** - Model training with early stopping
7. **Hyperparameter Tuning** - Dropout rate optimization
8. **Cross-Validation** - Stratified K-Fold evaluation
9. **Results Analysis** - Performance metrics and visualization
10. **Conclusions** - Key findings and future work

## ğŸ“ Academic Context

| Field            | Details                        |
| ---------------- | ------------------------------ |
| **Course**       | Machine Learning (DAMO-640-10) |
| **Semester**     | Fall 2025                      |
| **Student**      | Fabio dos Santos Prumucena     |
| **Student ID**   | NF100200                       |
| **Instructor**   | Professor Ahmed Eltahawi       |
| **Institution**  | GUSCanada                      |
| **Project Type** | Final Individual Assignment    |

## ğŸ”— Important Links

| Resource                  | URL                                                                                            |
| ------------------------- | ---------------------------------------------------------------------------------------------- |
| ğŸ¥ **Project Demo Video** | [https://youtu.be/t6vRSrpBsc8](https://youtu.be/t6vRSrpBsc8)                                   |
| ğŸ“¦ **GitHub Repository**  | [https://github.com/prumucena1979/MLFINAL](https://github.com/prumucena1979/MLFINAL)           |
| ğŸ—ƒï¸ **UCI Dataset Source** | [https://archive.ics.uci.edu/dataset/236/seeds](https://archive.ics.uci.edu/dataset/236/seeds) |
| ğŸ“š **TensorFlow Docs**    | [https://www.tensorflow.org/](https://www.tensorflow.org/)                                     |
| ğŸ”¬ **Scikit-learn Docs**  | [https://scikit-learn.org/](https://scikit-learn.org/)                                         |

## ğŸ™ Acknowledgments

This project was made possible by:

- **UCI Machine Learning Repository** - For hosting and maintaining the Seeds dataset
- **Original Researchers** - M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Åukasik, and S. Å»ak from the Institute of Agrophysics, Polish Academy of Sciences, Poland
- **Open Source Community** - For TensorFlow, Scikit-learn, and supporting libraries
- **Professor Ahmed Eltahawi** - For guidance and instruction throughout the course

## ğŸ“„ License

- **Project Code:** Available for educational and research purposes
- **Dataset:** Licensed under [Creative Commons Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)

## ğŸ“Š Technologies Used

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge&logo=python&logoColor=white)

---

<div align="center">

**â­ If you find this project helpful, please consider giving it a star!**

_This project demonstrates a complete, production-ready machine learning pipelineâ€”from data acquisition through model validationâ€”achieving state-of-the-art performance (99.91% accuracy) on the Seeds classification task._

**Made with â¤ï¸ by Fabio dos Santos Prumucena**

</div>
